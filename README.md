# ğŸ§  Veriphi: Neural Network Robustness Verification

A **GPUâ€‘accelerated verification stack** combining **attackâ€‘guided adversarial search** with **formal bound certification**  
(Î±â€‘, Î²â€‘CROWN via [autoâ€‘LiRPA](https://github.com/Verified-Intelligence/auto_LiRPA)).

It answers a simple but critical question:

> **â€œIs this model provably robust within Îµ under Lâˆ or L2 perturbations?â€**

â€¦and returns **verified / falsified**, with measured **runtime & memory**.

---

## ğŸš€ New Highlights

âœ… **Attackâ€‘Guided Verification:**  
   Fast falsification via FGSM + Iâ€‘FGSM, then formal verification using Î±â€‘, Î²â€‘CROWN.

âœ… **TRMâ€‘MLP Integration:**  
   Support for **Tiny Recursive Models (TRM)** â€” verified using the same unified pipeline.

âœ… **GPUâ€‘Accelerated Verification:**  
   Works seamlessly on **A100, RTX** or any CUDAâ€‘enabled GPU.

âœ… **Bound Comparison (CROWN vs Î±â€‘, Î²â€‘CROWN):**  
   Demonstrates verified fraction improvements through **adversarial training** and **tight bounds**.

---

## ğŸ”§ Install (reproducible)

```bash
# Clone
git clone https://github.com/inquisitour/veriphi-verification.git
cd veriphi-verification

# Python env
python3 -m venv venv
source venv/bin/activate

# Install (use CUDA wheels if you have GPU)
pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121
```

(Optional) install autoâ€‘LiRPA from source:
```bash
git clone https://github.com/Verified-Intelligence/auto_LiRPA.git
cd auto_LiRPA && git checkout v0.6.0
pip install -e .
cd ..
```

Verify your toolchain:
```bash
python verify_installation.py
```

---

## ğŸš€ Quick smoke test

```bash
# From repo root
source venv/bin/activate
export PYTHONPATH="$PWD/src:$PYTHONPATH"
python scripts/core_smoke.py
```

Minimal one-liner check:
```bash
python - <<'PY'
from core import create_core_system
from core.models import create_test_model, create_sample_input
core  = create_core_system(use_attacks=True, device='cpu')
model = create_test_model('tiny'); x = create_sample_input('tiny')
res   = core.verify_robustness(model, x, epsilon=0.1, norm='inf', timeout=30)
print(res.status.value, res.verified, f"{res.verification_time:.3f}s", "mem=", res.additional_info.get("memory_usage_mb"))
PY
```

---

## âš¡ GPU mode

Veriphi now fully supports **CUDA (A100, RTX, etc.)**.

```bash
# Enable GPU device
export VERIPHI_DEVICE=cuda
```

All engines, attacks, and models will automatically run on the GPU.

Check GPU availability:
```bash
python - <<'PY'
import torch
print("CUDA available:", torch.cuda.is_available())
print("GPUs:", torch.cuda.device_count())
for i in range(torch.cuda.device_count()):
    print(f"  GPU {i}:", torch.cuda.get_device_name(i))
PY
```

Run a GPU smoke test:
```bash
python scripts/gpu_smoke.py
```

Expected:  
```
CUDA available: True
âœ“ Attack-guided verification engine initialized on cuda
Verification result: verified ...
```

---

## ğŸ§ª Tests

```bash
# All tests (unit + integration + benchmarks)
export VERIPHI_DEVICE=cuda
python -m pytest -q
```

Or target a suite:
```bash
pytest tests/unit -q
pytest tests/integration -q
pytest tests/benchmarks -q
```

To run the full verification validation:
```bash
export VERIPHI_DEVICE=cuda && python run_tests.py --all --fix-tests
```

---

## ğŸ“Š Baselines

We keep results under:
- `data/baselines/cpu/` â€” CPU performance
- `data/baselines/gpu/` â€” GPU performance (A100, RTX, etc.)

### Generate CPU baselines
```bash
source venv/bin/activate
export PYTHONPATH="$PWD/src:$PYTHONPATH"
python scripts/run_cpu_baselines.py
```

### Generate GPU baselines
```bash
source venv/bin/activate
export PYTHONPATH="$PWD/src:$PYTHONPATH"
export VERIPHI_DEVICE=cuda
python scripts/run_gpu_baselines.py
```

Each run creates:
```
data/baselines/{cpu|gpu}/{cpu|gpu}_baselines_<timestamp>.csv
```

### Summarize baselines
```bash
python scripts/summarize_baselines.py
```

Writes grouped summaries to:
```
data/baselines/{cpu|gpu}/summary/summary_<timestamp>.csv
```

---

## ğŸ§© TRM Experiments

### Train TRMâ€‘MLP on MNIST
```bash
python scripts/trm_tiny_train.py
```

### Adversarially Fineâ€‘Tune
```bash
python scripts/trm_tiny_advtrain.py
```

### Verify Robustness (attack + formal)
```bash
python scripts/trm_tiny_verify.py
```

Outputs detailed logs for each Îµ and produces:
```
reports/trm_robustness_report.pdf
```

### Bound Comparison Sweep
```bash
python scripts/trm_tiny_sweep.py
```

Generates crossâ€‘method comparison:
- Î±â€‘CROWN
- Î²â€‘CROWN
- CROWN baseline

### Visual Report
```bash
python scripts/trm_visualize_results.py
```

Produces:
```
reports/trm_full_visual_report.pdf
```

### Streamlit UI
```bash
chmod +x run_streamlit_safe.sh
```
```bash
./run_streamlit_safe.sh
```

---

## ğŸ“Š Example Verified Fractions (TRM, Îµ = 0.03, Lâˆ)

| Bound Method | Avg Verified Fraction |
|---------------|----------------------:|
| CROWN         | 0.111 |
| Î±â€‘CROWN       | 0.143 |
| **Î²â€‘CROWN**   | **0.146 âœ…** |

---

## ğŸ—ï¸ Architecture Overview

```
src/core/
â”œâ”€â”€ verification/
â”‚   â”œâ”€â”€ base.py              # Verification interfaces + configs
â”‚   â”œâ”€â”€ alpha_beta_crown.py  # Î±,Î²â€‘CROWN formal bound engines
â”‚   â””â”€â”€ attack_guided.py     # Orchestrates attacks + verifier
â”œâ”€â”€ attacks/
â”‚   â”œâ”€â”€ base.py              # Attack interfaces
â”‚   â””â”€â”€ fgsm.py              # FGSM + iterative FGSM
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ test_models.py       # Tiny/Linear/Conv models
â”‚   â”œâ”€â”€ resnet_stubs.py      # ResNetâ€‘18/50 demo integration
â”‚   â””â”€â”€ trm_adapter.py       # TRMâ€‘MLP + recursive model adapter
â””â”€â”€ __init__.py              # VeriphiCore faÃ§ade
```

---

## ğŸ“ˆ Results Summary

```
âœ… TRM Adversarially Trained Model
Îµ = 0.03, norm = Lâˆ
verified = 7/10
falsified = 3/10
Î²â€‘CROWN > Î±â€‘CROWN > CROWN
```

Generated visual reports:
- `trm_robustness_report.pdf`
- `trm_compare_bounds_report.pdf`
- `trm_full_visual_report.pdf`
- `trm_hackathon_slide.pptx`
- `trm_hackathon_slide.pdf`

---

## ğŸ§­ Roadmap

| Stage | Goal | Status |
|--------|------|--------|
| 1ï¸âƒ£ | CUDA acceleration (A100 verified) | âœ… |
| 2ï¸âƒ£ | Add TRM MLP recursive architecture support | âœ… |
| 3ï¸âƒ£ | Adversarial + verified robustness training | âœ… |
| 4ï¸âƒ£ | Visual + PowerPoint autoâ€‘reporting | âœ… |
| 5ï¸âƒ£ | Heavy runs for 7M parameter TRM models | ğŸ”œ |

---

## ğŸ“’ Guides

- # [VSC5 Connection Guide (CLI)](./docs/vsc5_connection_readme.md)
- # [Benchmarking Guide](./docs/trm_scaling_readme.md)

---

## ğŸ“š References

- **autoâ€‘LiRPA Docs:** https://auto-lirpa.readthedocs.io/  
- **Î±,Î²â€‘CROWN Repo:** https://github.com/Verified-Intelligence/alpha-beta-CROWN  
- **Tiny Recursive Models:** https://github.com/SamsungSAILMontreal/TinyRecursiveModels  
- **VNNâ€‘COMP:** https://sites.google.com/view/vnn2024  

---

## ğŸ“„ License

MIT â€” see `LICENSE`.

---
 
â€œ*Bridging adversarial testing and formal verification for truly robust neural networks.*â€
